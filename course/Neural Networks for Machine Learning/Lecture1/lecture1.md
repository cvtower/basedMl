##Lecture1 介绍



####为什么需要机器学习

- 机器学习是从已有的输入和输出数据中进行学习，以应用于新的数据或场合
  - 识别物体：识别自然场景中的实物，人脸识别，语音识别
  - 识别反常现象(异常检测)：信用卡交易的反常序列，核电站传感器获取的不同信号
  - 预测：未来股票价格或货币汇率
- 数据集：
  - MNIST(手写数字识别，规模小)
  - ImageNet（1000中不同物体识别，130万张高清图片）
  - 语音识别任务：
    - pre-processing预处理（将声波转换为声学系数的向量）
    - the acoustic model声学模型（使用邻近的几个声学向量预测音节phoneme的可能性）
    - decoding解码（找到最适合声学数据的音节序列）
	
	DNN正在代替原来的机器学习算法用于构建声学模型，显著降低了错误率



####什么是神经网络
- 典型的皮质层神经元：整体结构（轴突产生分支发送信号给其他神经元，树突接收其他神经元的信号）；一个神经元的轴突与另一个神经元的树突进行通信的结构叫做突触，轴突产生刺激使得组织液中的电荷进入到后突触；当足够的电荷流入突触使得细胞膜去极化，这个神经元的轴突上的一些小山丘状结构产生刺激

- 突触：当轴突产生刺激，到达突触会释放携带化学物质的小泡，有不同的化学物质（积极和消极)，化学物质扩散过突触间隙，和接收神经元上的后突触膜的接收分子结合，导致膜发生形变，打开允许特定离子通过的通道，从而使得极性发生变化。突触通过改变化学物质囊泡的个数和接收分子的个数进行有效调节，他们很小和低耗能，使用局部信号进行调节。问题是他们如何决定怎样调节，也就是他们调节遵循的规则是什么？

- 模块化：大脑皮层不同的部分做不同的事情，损坏成年人的局部大脑会对其产生特定影响，但是大脑皮层整体看上去又是相似的，如果损坏幼儿的一部分大脑，他的其余部分可能就会分担这部分大脑的工作。大脑皮层是可通用化的，可以根据需要进化出某一特定的能力。


####简单的神经元模型
- 理想化模型(Idealized neurons)：去掉复杂却对于理解主要思想并不重要的细节；让我们可以应用数学计算和类比其他相似的系统；一旦理解了基本的思想，就容易增加复杂的部分使得模型更加可信。

- 线性神经元(Linear neurons):  
	<img src="./svg/1.svg" >

- 二元阈值神经元(Binary threshold neurons)：  

    <img src="./svg/2.svg" > <img src="./svg/2_2.svg" >
- 修正线性神经元(Rectified Linear neurons)：  

	<img src="./svg/3.svg" > <img src="./svg/3_2.svg" >
	
- Sigmoid神经元(Sigmoid neurons)：通常使用logistic function，<img src="./svg/4.svg" >  有连续的导数


- 随机二级制神经元(Stochastic binary neurons)


   可以将logistic sigmoid的输出看做产生刺激的概率，对于rectified linear units，输出可以看做产生spikes的速率，这是确定的，但是一旦我们计算出了产生spikes的速率，spikes真正产生的次数是一个随机过程，即泊松过程，Poisson rate。


####机器学习的一个简单例子（手写数字识别）


使用Tensorflow的练习代码：  

[手写数字识别](https://github.com/xxg1413/Tensorflow/blob/master/tutorial/008-tensorflow%20classification.py)  


[手写数字识别-CNN](https://github.com/xxg1413/Tensorflow/blob/master/tutorial/010-tensorflow%20CNN.py)  



更多代码参考kaggle-[Digit Recognizer](https://www.kaggle.com/c/digit-recognizer/kernels)

####机器学习的三种形式

- 有监督学习：从输入向量中学习预测输出（回归，分类），首先选择一个model-class（即输入到输出的映射），学习就是调增参数使得输出值和真实目标接近

- 增强学习：学习选择行为来最大化效益。输出是一个行为或一系列行为，唯一的监督信号是偶尔的有监督的奖励，目标是选择行为最大化未来的奖励，通常使用一个折现因子，因此不用考虑太远的未来。增强学习是困难的，因为奖励是延时的，所以很难确定我们哪一步做对做错，而且有监督的奖励只是时而出现，并不提供太多信息，所以不能学习很多参数。

- 无监督学习：发现输入的好的本质的表示形式；提供压缩低维的特征表示（PCA线性压缩）；提供输入的经济的高维表示（如Binary features，或接近于0的real-valued features）

