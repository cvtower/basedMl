# 实时对象侦测


数据科学家

        https://github.com/ClimbsRocks

        https://github.com/rhiever

        https://github.com/loliverhennigh


* Art Generation
* Image Classifier
* Earthquake Prediction
* Language Translation
* Linear Regression
* Music Generation
* Sentiment Analysis
* Text Based Chatbot

https://www.cs.waikato.ac.nz/ml/weka/ java api frameworks
https://github.com/ivan-vasilev/neuralnetworks java 库
https://software.intel.com/zh-cn/ai-academy/students/kits  intel ml 教程
http://neuralnetworksanddeeplearning.com/index.html  基础

code to accompany blog posts  
tensorflow 基础
1. [Transfer learning from multiple pre-trained computer vision models](https://www.oreilly.com/ideas/transfer-learning-from-multiple-pre-trained-computer-vision-models)
In this short blog post I describe the (somewhat under-utilized) method of combining multiple pre-trained cv models using stacking, to enhance classification results on a new dataset. 

2.  Go with the Flow: Up and Running with TensorFlow
3.  Understanding TensorFlow Basics
4.  Convolutional Neural Networks
5.  Text I: Working with Text and Sequences, and TensorBoard Visualization.
6.  Text II: Word Vectors, Advanced RNN, and Embedding Visualization.
7.  TensorFlow Abstractions and Simplications.
8.  Queues, Threads, and Reading Data.
9.  Distributed TensorFlow.
10. Exporting and Serving Models with TensorFlow.


Check out the associated [repo](https://github.com/Hezi-Resheff/Oreilly-OSCON2017-Learning-TensorFlow) from our [OSCON2017](https://conferences.oreilly.com/oscon/oscon-tx) [training](https://conferences.oreilly.com/oscon/oscon-tx/public/schedule/detail/57856). 

---
If you like the book, please rate it on [Amazon](https://www.amazon.com/Learning-TensorFlow-Guide-Building-Systems/dp/1491978511/ref=sr_1_2?ie=UTF8&qid=1505770781&sr=8-2&keywords=resheff) :) 




- [Densely Connected Convolutional Network](http://arxiv.org/abs/1608.06993) implemented in the [DenseNet folder](https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/DenseNet)

- [Visualizing and Understanding Convolutional Networks](https://arxiv.org/pdf/1311.2901v1) implemented in the [DeconvNet folder](https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/DeconvNet)

- [Improving Stochastic Gradient Descent With Feedback](https://arxiv.org/pdf/1611.01505v1.pdf) implemented in the [Eve folder](https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/Eve)

- [Colorful Image Colorization](https://arxiv.org/abs/1603.08511) implemented in the [Colorful folder](https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/Colorful)

- [Deep Feature Interpolation for Image Content Changes](https://arxiv.org/pdf/1611.05507v1.pdf) implemented in the [DFI folder](https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/DFI)

- Several Generative Adversarial Networks (GAN) models and techniques in the [GAN folder](https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/GAN)

- [pix2pix](https://arxiv.org/pdf/1611.07004v1.pdf) in the [pix2pix folder](https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/pix2pix)

- [InfoGAN](https://arxiv.org/abs/1606.03657) in the [InfoGAN folder](https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/InfoGAN)

- [WassersteinGAN](https://arxiv.org/abs/1701.07875) in the [WassersteinGAN folder](https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/WassersteinGAN) and [WGAN-GP folder](https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/WGAN-GP) for a tensorflow implementation.

- [BEGAN](https://arxiv.org/pdf/1703.10717.pdf) in the [BEGAN folder](https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/BEGAN)

- [Scaling the Scattering Transform: Deep Hybrid Networks](https://arxiv.org/abs/1703.08961) in the [ScatteringTransform folder](https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/ScatteringTransform)

- [Sobolev Training for Neural Networks](https://arxiv.org/abs/1706.04859) in the [Sobolev folder](https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/Sobolev)

- [Self-Normalizing Networks](https://arxiv.org/pdf/1706.02515.pdf) in the [SELU folder](https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/SELU)

-----------------------------------------------
2018 论文复现赛
要了解文中提到的复现赛详情，看这里：http://www.cs.mcgill.ca/~jpineau/ICLR2018-ReproducibilityChallenge.html
  
<自然》对1500名科学家的调查：http://www.nature.com/news/1-500-scientists-lift-the-lid-on-reproducibility-1.19970?WT.mc_id=FBK_NatureNews
  
ICML2017论文ReproducibilityinMachineLearning-BasedStudies:AnExampleofTextMining：https://openreview.net/pdf?id=By4l2PbQ-
  
  QZ报道：https://qz.com/1118671/the-titans-of-ai-are-getting-their-work-double-checked-by-students/

  -------------------------------------------------

 论文
 
 DSLR-QualityPhotosonMobileDeviceswithDeepConvolutionalNetworks 
 StackGAN:TexttoPhoto-realisticImageSynthesiswithStackedGenerativeAdversarialNetworks 
 High-QualityCorrespondenceandSegmentationEstimationforDual-LensSmart-PhonePortraits 
 PhotographicImageSynthesiswithCascadedRefinementNetworks 
 FoveaNet:Perspective-awareUrbanSceneParsing 
 ArbitraryStyleTransferinReal-timewithAdaptiveInstanceNormalization
 Dense-CaptioningEventsinVideos 
 TowardsDiverseandNaturalImageDescriptionsviaaConditionalGAN 
 Weakly-supervisedlearningofvisualrelations 
 InferringandExecutingProgramsforVisualReasoning 
 TurningCornersintoCameras:PrinciplesandMethods 
 GeneratingHigh-QualityCrowdDensityMapsusingContextualPyramidCNNs 
 DeepRoadMapper:ExtractingRoadTopologyfromAerialImages 




----------------------------------
https://pair-code.github.io/facets/可嵌入到jupyter notebook 的数据可视化工具
代码：https://github.com/PAIR-code/facets

---------------------------

语音识别工具：https://github.com/kaldi-asr/kaldi

示例：https://github.com/kaldi-asr/kaldi/tree/master/egs/ami/s5/local/tfrnnlm 

---------------------------------------------

https://github.com/DeepScale/SqueezeNet 
两个小的模型的输出特征拼在一起，然后再进行分配，拼成一个大模型。然后还可以增加Batchnorm、dropout、L2 
我们发现ResNet效果是最好的，DenseNet效果紧随其后。VGG，Inceptionv3效果差一点。最差的是AlexNet和SqueezeNet
不同的模型集成手段，比如平均Bagging，BaggingEnsembleSelection，还有AttentionStacking，AttentionStacking是我们自己加入的一个东西，效果还不错。

http://www.sohu.com/a/163567410_114877

 -------------------------------------

 http://deepcognition.ai/  深度学习云，速度挺快

 tensorflow eager 版本  使得图形化编程即时化 可读性更强
 谷歌研究博客地址：https://research.googleblog.com/2017/10/eager-execution-imperative-define-by.html
 
 GitHub代码地址：https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/README.md代码
 
 使用手册：https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/g3doc/guide.md 
 
 
Anh Nguyen的论文《Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images》
  

  http://nbviewer.jupyter.org/github/BVLC/caffe/blob/master/examples/00-classification.ipynb

  https://github.com/yosinski/deep-visualization-toolbox

  见于Christian Szegedy的论文《Intriguing properties of neural networks
》

Understanding Deep Image Representations by Inverting Them

A Neural Algorithm of Artistic Style


至于Gram矩阵为什么能作为重建风格的依据，论文《Demystifying Neural Style Transfer》
https://github.com/yosinski/deep-visualization-toolbox

https://github.com/frombeijingwithlove/dlcv_for_beginners/tree/master/random_bonus/gan_n_cgan_2d_example

https://zhuanlan.zhihu.com/p/27343585


https://github.com/devnag/pytorch-generative-adversarial-networks

https://github.com/mokemokechicken/keras_np
i
http://blog.csdn.net/sinat_33761963/article/details/53521206


tensorflow框架下有一个序列到序列进行翻译的学习案例。 
文档可以参见https://www.tensorflow.org/versions/r0.11/tutorials/seq2seq/index.html 
代码可以参见https://github.com/tensorflow/tensorflow/tree/master/tensorflow/models/rnn/translate 

生成字符级别的语言模型
上一个笔记中将的语言生成模型是针对word来做的，这里的原理是完全一样的，只是针对chart来做。将所有chart，包括标点符号全部作为输入。大致的结构如下：

![QQ截图20161027132426.png-71.6kB][131]

这个案例的代码可以见：https://gist.github.com/karpathy/d4dee566867f8291f086

来看一下模型在学习过程中的进展是如何的： 
学习第100轮的时候，还很混乱 
QQ截图20161027132843.png-14.7kB

学习第300轮之后，已经能正确得插入词与词之间的空格 
QQ截图20161027132851.png-20.2kB

第500轮之后，知道了要加句号在某个位置，并且句号之后加一个空格 
QQ截图20161027132858.png-14.7kB

700-900轮时，已经非常像英文的句子，已经学会了使用引号，省略号等，学出来的词也已经是标准的英文单词 
QQ截图20161027132905.png-11.4kB

1200轮的时候，能识别人名要大写，并且单词和句子也几乎是正确的。 
QQ截图20161027132912.png-21.7kB

所以，RNN与学习的时候是一个逐步学习的过程。

3.2 生成维基百科
同样的原理，如果喂给RNN的是维基百科的内容，那么它也能在学习之后模仿写出维基百科。 
已经有小伙伴整理了一部分维基百科的数据做成text的格式，有兴趣的小伙伴可以去下载数据测试一下。 
数据地址：http://cs.stanford.edu/people/karpathy/char-rnn/wiki.txt

3.3 生成模型写食谱
同样，RNN也可以去模仿写食谱。这个案例的具体信息见以下链接。 
案例：https://gist.github.com/nylki/1efbaa36635956d35bcc 
代码：https://gist.github.com/karpathy/d4dee566867f8291f086 
数据：http://www.ffts.com/recipes/lg/lg32965.zip

3.4 生成模型写奥巴马演讲稿
还有一些小伙伴尝试了用RNN去写奥巴马的演讲稿。 
数据下载地址： 
https://medium.com/@samim/obama-rnn-machine-generated-political-speeches-c8abd18a2ea0#.9sb793kbm

3.5 合成音乐
音乐也是一个时序的一个任务。将乐谱用一种方式表示出来输入RNN，预测完之后，再把它转换成音符。 
具体的过程请见blog：https://highnoongmt.wordpress.com/2015/05/22/lisls-stis-recurrent-neural-networks-for-folk-music-generation/

还有一个更高级的合成音乐案例，这里面还涉及到了乐理的一些知识， 
具体请看blog：http://www.hexahedria.com/2015/08/03/composing-music-with-recurrent-neural-networks/

[13lqh7xlyv2owk5rw4fyslus2d/QQ%E6%88%AA%E5%9B%BE20161027145714.png


目前正在进行更复杂的内存结构的趋势。端到端内存网络允许网络在输出之前读取相同的输入序列多次，在每一步更新内存内容。例如，通过对输入的故事进行多个推理步骤来回答问题

在未来，我们可能会看到记忆和注意力机制之间的更清晰的区别，也许是沿着强化学习神经图灵机的路线，它试图学习访问模式来处理外部接口。

http://deeplearning.cs.cmu.edu/ 课程

https://github.com/dennybritz/deeplearning-papernotes 重要论文汇总

http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/


https://github.com/rockingdingo/deepnlp

https://stackoverflow.com/questions/40601552/visualizing-attention-activation-in-tensorflow


---------------------------------------------

